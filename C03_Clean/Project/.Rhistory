names(merge_act)<-sub("^f","FreqDomainOf",names(merge_act))
names(merge_act)<-sub("BodyAccJerkMag","AccelJerkMagnitudeBody",names(merge_act))
names(merge_act)<-sub("BodyAccJerk","AccelJerkSignalBody",names(merge_act))
names(merge_act)<-sub("BodyAccMag","AccelerationMagnitudeBody",names(merge_act))
names(merge_act)<-sub("BodyAcc","AccelerationSignalBody",names(merge_act))
names(merge_act)<-sub("BodyGyroJerkMag","GyroJerkMagnitudeBody",names(merge_act))
names(merge_act)<-sub("BodyGyroJerk","GyroJerkSignalBody",names(merge_act))
names(merge_act)<-sub("BodyGyroMag","GyroscopeMagnitudeBody",names(merge_act))
names(merge_act)<-sub("BodyGyro","GyroscopeSignalBody",names(merge_act))
names(merge_act)<-sub("GravityAccMag","AccelerationMagnitudeGravity",names(merge_act))
names(merge_act)<-sub("GravityAcc","AccelerationSignalGravity",names(merge_act))
names(merge_act)<-sub("mean\\(\\)","AverageNumber",names(merge_act))
names(merge_act)<-sub("std\\(\\)","StandardDeviation",names(merge_act))
merge_act2<-merge_act
class(merge_act2[,2])
merge_act2[,2]<-as.character(merge_act2[,2])
class(merge_act2[,2])
##Create 2nd data set
final_row<-c()
merge_act[,2]<-as.character(merge_act[,2])
for(i in 1:30){
smerge_i<-subset(merge_act,merge_act[,1]==i)
subrow<-c(i,"AllActivity")
for(j in 4:63){
subrow<-c(subrow,mean(smerge_i[,j]))
}
final_row<-rbind(final_row,subrow)
}
for(k in 1:6){
amerge_k<-subset(merge_act,merge_act[,3]==k)
actrow<-c("AllSubject",amerge_k[,2])
for(l in 4:63){
actrow<-c(actrow,mean(amerge_k[,l]))
}
final_row<-rbind(final_row,actrow)
}
actrow
View(amerge_k)
actrow<-c("AllSubject",amerge_k[,2])
actrow<-c()
actrow<-c("AllSubject",amerge_k[,2])
View(amerge_k)
View(smerge_i)
View(final_row)
mean(amerge_k[,4])
warning()
warnings()
final_row<-c()
merge_act[,2]<-as.character(merge_act[,2])
for(i in 1:30){
smerge_i<-subset(merge_act,merge_act[,1]==i)
subrow<-c(i,"AllActivity")
for(j in 4:63){
subrow<-c(subrow,mean(smerge_i[,j]))
}
final_row<-rbind(final_row,subrow)
}
for(m in 1:6){
amerge_k<-subset(merge_act,merge_act[,3]==m)
actrow<-c("AllSubject",amerge_m[,2])
for(n in 4:63){
actrow<-c(actrow,mean(amerge_m[,n]))
}
final_row<-rbind(final_row,actrow)
}
final_row<-c()
merge_act[,2]<-as.character(merge_act[,2])
for(i in 1:30){
smerge_i<-subset(merge_act,merge_act[,1]==i)
subrow<-c(i,"AllActivity")
for(j in 4:63){
subrow<-c(subrow,mean(smerge_i[,j]))
}
final_row<-rbind(final_row,subrow)
}
for(m in 1:6){
amerge_m<-subset(merge_act,merge_act[,3]==m)
actrow<-c("AllSubject",amerge_m[,2])
for(n in 4:63){
actrow<-c(actrow,mean(amerge_m[,n]))
}
final_row<-rbind(final_row,actrow)
}
aaa<-c("AllSubject",amerge_m[,2])
actrow<-c()
final_row<-c()
merge_act[,2]<-as.character(merge_act[,2])
for(i in 1:30){
smerge_i<-subset(merge_act,merge_act[,1]==i)
subrow<-c(i,"AllActivity")
for(j in 4:63){
subrow<-c(subrow,mean(smerge_i[,j]))
}
final_row<-rbind(final_row,subrow)
}
for(m in 1:6){
amerge_m<-subset(merge_act,merge_act[,3]==m)
actrow<-c("AllSubject",amerge_m[1,2])
for(n in 4:63){
actrow<-c(actrow,mean(amerge_m[,n]))
}
final_row<-rbind(final_row,actrow)
}
View(final_row)
write.table(final_row,"A.txt")
row2<-as.data.frame(final_row)
write.table(row2,"B.txt",row.name=F)
View(merge_act)
final<-as.data.frame(final_row)
final_names<-names(merge_act)
final_names<-final_names[-3]
names(final)<-c(final_names)
View(final)
final<-as.data.frame(final_row)
final_names<-names(merge_act)
final_names<-final_names[-3]
final_names<-sub("^T","Average-T",final_names)
final_names<-sub("^F","Average-F",final_names)
names(final)<-c(final_names)
View(final)
source('~/DataScience/datasciencecoursera/C03_Clean/Project/run_analysis.R')
run_analysis
run_analysis()
source('~/DataScience/datasciencecoursera/C03_Clean/Project/run_analysis.R')
run_analysis()
read.table("DataSet.txt")
code<-read.table("DataSet.txt")
View(code)
source('~/DataScience/datasciencecoursera/C03_Clean/Project/run_analysis.R')
run_analysis()
code<-read.table("DataSet.txt")
View(code)
code<-read.table("DataSet.txt",header=T)
View(code)
write.table(names(code),"CodeBook.txt")
a<-read.table("Tidy.txt")
a<-read.table("Tidy.txt")
View(a)
## Create one R script called run_analysis.R that does the following:
## 1. Merges the training and the test sets to create one data set.
## 2. Extracts only the measurements on the mean and standard deviation for each measurement.
## 3. Uses descriptive activity names to name the activities in the data set
## 4. Appropriately labels the data set with descriptive activity names.
## 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
if (!require("data.table")) {
install.packages("data.table")
}
if (!require("reshape2")) {
install.packages("reshape2")
}
require("data.table")
require("reshape2")
# Load the activity labels and data column names
activity_labels <- read.table(".\\activity_labels.txt")[,2]
features <- read.table(".\\features.txt")[,2]
# Extract only the measurements on the mean and standard deviation for each measurement.
extract_features <- grepl("mean|std", features)
# Load and process X_test & y_test data.
X_test <- read.table(".\\test\\X_test.txt")
y_test <- read.table(".\\test\\y_test.txt")
subject_test <- read.table(".\\test\\subject_test.txt")
names(X_test) = features
# Extract only the measurements on the mean and standard deviation for each measurement.
X_test = X_test[,extract_features]
# Load activity labels
y_test[,2] = activity_labels[y_test[,1]]
names(y_test) = c("Activity_ID", "Activity_Label")
names(subject_test) = "subject"
# Bind data
test_data <- cbind(as.data.table(subject_test), y_test, X_test)
# Load and process X_train & y_train data.
X_train <- read.table(".\\train\\X_train.txt")
y_train <- read.table(".\\train\\y_train.txt")
subject_train <- read.table(".\\train\\subject_train.txt")
names(X_train) = features
# Extract only the measurements on the mean and standard deviation for each measurement.
X_train = X_train[,extract_features]
# Load activity data and bind the data
y_train[,2] = activity_labels[y_train[,1]]
names(y_train) = c("Activity_ID", "Activity_Label")
names(subject_train) = "subject"
train_data <- cbind(as.data.table(subject_train), y_train, X_train)
# Merge test and train data
data = rbind(test_data, train_data)
id_labels = c("subject", "Activity_ID", "Activity_Label")
data_labels = setdiff(colnames(data), id_labels)
melt_data = melt(data, id = id_labels, measure.vars = data_labels)
# Apply mean function to dataset using dcast function
tidy_data = dcast(melt_data, subject + Activity_Label ~ variable, mean)
write.table(tidy_data, file = ".\\Tidy_DATA_DSR.txt")
seted("data")
setwd("Data")
## Create one R script called run_analysis.R that does the following:
## 1. Merges the training and the test sets to create one data set.
## 2. Extracts only the measurements on the mean and standard deviation for each measurement.
## 3. Uses descriptive activity names to name the activities in the data set
## 4. Appropriately labels the data set with descriptive activity names.
## 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
if (!require("data.table")) {
install.packages("data.table")
}
if (!require("reshape2")) {
install.packages("reshape2")
}
require("data.table")
require("reshape2")
# Load the activity labels and data column names
activity_labels <- read.table(".\\activity_labels.txt")[,2]
features <- read.table(".\\features.txt")[,2]
# Extract only the measurements on the mean and standard deviation for each measurement.
extract_features <- grepl("mean|std", features)
# Load and process X_test & y_test data.
X_test <- read.table(".\\test\\X_test.txt")
y_test <- read.table(".\\test\\y_test.txt")
subject_test <- read.table(".\\test\\subject_test.txt")
names(X_test) = features
# Extract only the measurements on the mean and standard deviation for each measurement.
X_test = X_test[,extract_features]
# Load activity labels
y_test[,2] = activity_labels[y_test[,1]]
names(y_test) = c("Activity_ID", "Activity_Label")
names(subject_test) = "subject"
# Bind data
test_data <- cbind(as.data.table(subject_test), y_test, X_test)
# Load and process X_train & y_train data.
X_train <- read.table(".\\train\\X_train.txt")
y_train <- read.table(".\\train\\y_train.txt")
subject_train <- read.table(".\\train\\subject_train.txt")
names(X_train) = features
# Extract only the measurements on the mean and standard deviation for each measurement.
X_train = X_train[,extract_features]
# Load activity data and bind the data
y_train[,2] = activity_labels[y_train[,1]]
names(y_train) = c("Activity_ID", "Activity_Label")
names(subject_train) = "subject"
train_data <- cbind(as.data.table(subject_train), y_train, X_train)
# Merge test and train data
data = rbind(test_data, train_data)
id_labels = c("subject", "Activity_ID", "Activity_Label")
data_labels = setdiff(colnames(data), id_labels)
melt_data = melt(data, id = id_labels, measure.vars = data_labels)
# Apply mean function to dataset using dcast function
tidy_data = dcast(melt_data, subject + Activity_Label ~ variable, mean)
write.table(tidy_data, file = ".\\Tidy_DATA_DSR.txt")
setwd("s1")
## Create one R script called run_analysis.R that does the following:
## 1. Merges the training and the test sets to create one data set.
## 2. Extracts only the measurements on the mean and standard deviation for each measurement.
## 3. Uses descriptive activity names to name the activities in the data set
## 4. Appropriately labels the data set with descriptive activity names.
## 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
if (!require("data.table")) {
install.packages("data.table")
}
if (!require("reshape2")) {
install.packages("reshape2")
}
require("data.table")
require("reshape2")
# Load the activity labels and data column names
activity_labels <- read.table(".\\activity_labels.txt")[,2]
features <- read.table(".\\features.txt")[,2]
# Extract only the measurements on the mean and standard deviation for each measurement.
extract_features <- grepl("mean|std", features)
# Load and process X_test & y_test data.
X_test <- read.table(".\\test\\X_test.txt")
y_test <- read.table(".\\test\\y_test.txt")
subject_test <- read.table(".\\test\\subject_test.txt")
names(X_test) = features
# Extract only the measurements on the mean and standard deviation for each measurement.
X_test = X_test[,extract_features]
# Load activity labels
y_test[,2] = activity_labels[y_test[,1]]
names(y_test) = c("Activity_ID", "Activity_Label")
names(subject_test) = "subject"
# Bind data
test_data <- cbind(as.data.table(subject_test), y_test, X_test)
# Load and process X_train & y_train data.
X_train <- read.table(".\\train\\X_train.txt")
y_train <- read.table(".\\train\\y_train.txt")
subject_train <- read.table(".\\train\\subject_train.txt")
names(X_train) = features
# Extract only the measurements on the mean and standard deviation for each measurement.
X_train = X_train[,extract_features]
# Load activity data and bind the data
y_train[,2] = activity_labels[y_train[,1]]
names(y_train) = c("Activity_ID", "Activity_Label")
names(subject_train) = "subject"
train_data <- cbind(as.data.table(subject_train), y_train, X_train)
# Merge test and train data
data = rbind(test_data, train_data)
id_labels = c("subject", "Activity_ID", "Activity_Label")
data_labels = setdiff(colnames(data), id_labels)
melt_data = melt(data, id = id_labels, measure.vars = data_labels)
# Apply mean function to dataset using dcast function
tidy_data = dcast(melt_data, subject + Activity_Label ~ variable, mean)
write.table(tidy_data, file = ".\\Tidy_DATA_DSR.txt")
source('~/DataScience/datasciencecoursera/C03_Clean/Project/Data/s1/s1.R')
setwd("..")
source('~/DataScience/datasciencecoursera/C03_Clean/Project/Data/s1.R')
setwd("..")
source('~/DataScience/datasciencecoursera/C03_Clean/Project/Data/s1.R')
setwd("..")
source('~/DataScience/datasciencecoursera/C03_Clean/Project/Data/s1.R')
setwd("Project")
setwd("Data")
source('~/DataScience/datasciencecoursera/C03_Clean/Project/Data/s1.R')
setwd("..")
setwd("UCI HAR Dataset")
source('~/DataScience/datasciencecoursera/C03_Clean/Project/UCI HAR Dataset/s1.R')
source("run_analysis.R")
setwd("..")
a<-read.table("Final.txt")
View(a)
a<-read.table("Final.txt")
View(a)
source('~/DataScience/datasciencecoursera/C03_Clean/Project/s3.R')
source('~/DataScience/datasciencecoursera/C03_Clean/Project/s3.R')
a<-read.table("Final.txt")
View(a)
#reading training set
X_train <- read.table('./UCI HAR Dataset/train/X_train.txt')
Y_train <- read.table('./UCI HAR Dataset/train/Y_train.txt')
train_subject <- read.table('./UCI HAR Dataset/train/subject_train.txt')
train <- cbind(X_train,Y_train,train_subject)
# reading test set
X_test <- read.table('./UCI HAR Dataset/test/X_test.txt')
Y_test <- read.table('./UCI HAR Dataset/test/Y_test.txt')
test_subject <- read.table('./UCI HAR Dataset/test/subject_test.txt')
test <- cbind(X_test,Y_test,test_subject)
# joining the dataset
alldata<- rbind(train,test)
features <- read.table('./UCI HAR Dataset/features.txt')
features <- features[,2]
matches <- grep("(mean|std)\\(\\)", features)
selected <- alldata[,matches]
names<-features[matches]
# names <- gsub("-mean\\(\\)", "Mean",names)
# names <- gsub("-std\\(\\)", "StdDev",names)
names <- gsub('-','',names)
names <- gsub('BodyBody','Body',names)
#step 3,4
activity <- read.table('./UCI HAR Dataset/activity_labels.txt')
Y <- rbind(Y_train,Y_test)
activity_label <- activity[Y[,1],2]
colnames(selected) <- names
subject <- rbind(train_subject,test_subject)
colnames(subject)<-'subject'
final <- cbind(subject, selected, activity_label)
#step 5
library(plyr)
colmeans <- function(data){colMeans(data[,-c(1,68)])}
tidytable <- ddply(final, .(subject,activity_label),colmeans)
write.table(tidytable,'tidydata.txt',row.names=FALSE)
b<-read.table("tidydata.txt")
View(b)
b<-read.table("tidydata.txt")
View(b)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv",destfile="q1csv.csv",method="curl")
q1csv<-read.csv("q1csv.csv")
?strsplit
strsplit(q1csv,"wgtp")
strsplit(q1csv,split="wgtp")
strsplit(names(q1csv),"wgtp")
strsplit(names(q1csv),split="wgtp")
names(q1csv)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv",destfile="q2csv.csv",method="curl")
q2csv<-read.csv("q2csv.csv")
View(`q2csv`)
q2no<-subset(q2csv,q2csv[5:194,5])
q2no<-q2csv[5:194,5]
head(q2no)
q2no1<-as.character(q2no)
?sub
q2no2<-sub(q2no1,pattern=" ")
q2no2<-sub(pattern=" ",q2no1)
q2no2<-sub(pattern=" ",x=q2no1)
q2no2<-sub(pattern=" ",replacement="",x=q2no1)
q2no3<-sub(pattern=",",replacement="",x=q2no2)
q2no3<-sub(pattern=",",replacement="",x=q2no3)
q2no3<-sub(pattern="",replacement="",x=q2no3)
q2no3<-sub(pattern=" ",replacement="",x=q2no3)
q2no4<-as.numeric(q2no3)
?sum
?mean
mean(q2no4)
countryNames<-q2csv[5:194,4]
countryNames<-as.character(countryNames)
grep("^United",countryNames)
countryNames[99]
countryNames[186]
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", destfile="q4.csv", method="curl")
q4csv<-read.csv("q4csv.csv")
q4csv<-read.csv("q4.csv")
View(`q4csv`)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv",destfile="q4e.csv",method="curl")
q4ecsv<-read.csv("q4e.csv")
View(`q4ecsv`)
q4names<-q4csv[5:194,1]
q4names<-q4csv[5:194,1],-as.character(q4names)
q4names<-as.character(q4names)
names(q4names)<-c(NCode)
names(q4names)<-c("NCode")
head(q4names)
q4names<-data.frame()
q4names[,1]<-q4csv[5:194,1]
q4names<-q4csv[5:194,1]
q4names<-as.character(q4names)
q4n<-data.frame()
q4n[,1]<-q4names
cbind(q4n,q4names)
q4names<-q4csv[5:194,1:2]
names(q4names)<-c("NCode","Rank")
head(q4names,2)
?merge
q4merge<-merge(q4names,q4ecsv,by.x="NCode",by.y="CountryCode")
View(`q4merge`)
?grep
q4grep<-grep(pattern="Fiscal year end",x=q4merge)
q4grep<-grep(pattern="Fiscal year end",x=q4merge[,11])
q4merge2<-q4merge[q4grep,]
View(`q4merge2`)
q4grep2<-grep(pattern="June",x=q4merge2,ignore.case=T)
q4grep2<-grep(pattern="June",x=q4merge2[,11],ignore.case=T)
q4grep2<-grep(pattern="June",x=q4merge2[,11],ignore.case=F)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
head(amzn)
View(amzn)
tail(amzn)
class(amzn[1,])
class(amzn[,1])
q5date<-amzn[,1]
?as.date
library(lubridate)
install.packages("lubridate")
library(lubridate)
head(q5date)
q5date<-row.names(amzn)
q5date<-amzn$row.names
q5date<-rownames(amzn)
q5date<-rownames(amzn,do.NULL=F)
q5date<-rownames(amzn,do.NULL=T)
q5date<-rownames(amzn)
rownames(amzn)
amazon<as.data.frame(amzn)
amazon<-as.data.frame(amzn)
q5date<-rownames(amazon)
ymd(q5date[1])
q5date2<-as.date(q5date)
q5date2<-as.Date(q5date)
q5date2
head(q5date2(%Y))
q5date2(%Y)
head(year(q5date2))
q52007<-q5date2[year(q5date2)==2007]
q52007
head(weekdays(q52007))
q507mon<-q52007[weekdays(q52007)=="Mon"]
q507mon
q507mon<-q52007[weekdays(q52007)==Mon]
q507mon<-q52007[weekdays(q52007)==2]
q507mon
class(q52007)
weekdays[q52007==2]
weekdays(q5200)==2
weekdays(q52007)==2
weekdays(q52007)=="Monday"
weekdays(q52007)=="周一"
q507mon<-q52007[weekdays(q52007)=="周一"]
length(q507mon)
q52012<-q5date2[year(q5date2)==2012]
q512mon<-q52012[weekdays(q52012)=="周一"]
length(q512mon)
length(q52012)
swirl
library(swirl)
swirl()
my_vector<-c(1:20)
my_vector<-1:20
my_vector
dim(my_vector)
length(my_vector)
dim(my_vector)<-c(4,5)
dim(my_vector)
attributes(my_vector)
my_vector
class(my_vector)
my_matirx<-my_vetor
my_matirx<-my_vector
my_matrix<-my_vector
?matrix
my_matrix2<-matrix(nrow=4,ncol=5)
my_matrix2<-matrix(data=1:20,nrow=4,ncol=5)
identical(my_matrix,my_matrix2)
patients<-c("Bill","Gina","Kelly","Sean")
cbind(patient,my_matirx)
cbind(patients,my_matirx)
cbind(patients,my_matrix)
my_data<-data.fram(patients,my_matrix)
my_data<-data.frame(patients,my_matrix)
my_data
class(my_data)
cnames<-("patients","age","weight","bp","rating","test")
cnames<-("patient","age","weight","bp","rating","test")
cnames<-c("patient","age","weight","bp","rating","test")
colnames(my_data)<-cnames
my_data
install_from_swirl("Getting and Cleaning Data")
?read.table
